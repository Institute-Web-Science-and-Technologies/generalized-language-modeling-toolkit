#what to do
createNGramChunks = true
createSecondLevelNGramChunks = true
aggregateNGramChunks = true
sortNGrams = true


#wikipedia bzip file
wikiXmlPath = /var/lib/datasets/wikipedia/barwiki-20120710-pages-articles.xml.bz2
#wikiXmlPath = /var/lib/datasets/wikipedia/dewiki-20120204-pages-articles.xml.bz2

germanWikiText = /var/lib/datasets/out/wikipedia/testfile.txt
letterGraph = /var/lib/datasets/letterGraph

#reutersXmlPath
reutersXmlPath = /var/lib/datasets/Reuters-CV1-CV2/unzip/

#enronXmlPath
enronPath = /var/lib/datasets/Enron-Mail/maildir/

#DGTTMPath
DGTTMPath = /var/lib/datasets/JRC-Acquis-2012/unzip/

DGTTMLanguage = DE

keystrokesWindowSize = 7

nGramInput= /var/lib/datasets/out/wikipedia/frwikinormalized.txt
parsedNGrams = /var/lib/datasets/out/wikipedia/frwiki5grams.txt
sortedNGrams = /var/lib/datasets/out/wikipedia/sortedNGrams.txt
nGramLength = 5

googleNgramsPath = /var/lib/datasets/google-ngrams/ger-all-5gram-20090715/
googleNgramsMergedPath = /var/lib/datasets/out/googlengrams.txt

parsedWikiOutputPath = /var/lib/datasets/out/wikipedia/wikiout.txt
parsedReutersOutputPath = /var/lib/datasets/out/reutersout.txt
parsedEnronOutputPath = /var/lib/datasets/out/enronout.txt
parsedDGTTMOutputPath = /var/lib/datasets/out/dgttmout.txt

normalizedWikiOutputPath = /var/lib/datasets/out/wikipedia/enwikinormalized.txt
normalizedReutersOutputPath = /var/lib/datasets/out/reutersnormalized.txt
normalizedEnronOutputPath = /var/lib/datasets/out/enronnormalized.txt
normalizedDGTTMOutputPath = /var/lib/datasets/out/dgttmnormalized.txt

wikiLinksOutputPath = /var/lib/datasets/out/wikipedia/wikilinks.txt

ngramDownloadPath = googlebooks-spa-all-5gram-20090715
ngramDownloadOutputPath = /var/lib/datasets/out/

googleNgramsPath = /var/lib/datasets/google-ngrams/eng-all-5gram-20090715
googleNgramsMergedPath = /var/lib/datasets/out/google-ngrams/engooglengramsmerged.txt

#TypologyTrainer
testDb = /var/lib/databases/degooglengrams.db

#BUILD NGRAMS FROM WIKI
nGramKeyFile = /var/lib/datasets/out/wikipedia/letteroutput/keys.txt
nGramsNotAggregatedPath = /var/lib/datasets/out/wikipedia/letteroutput
nGramsAggregatedPath = /var/lib/datasets/out/wikipedia/letteroutput/aggregated

#CREATE TYPOLOGY EDGES
typologyEdgesPathNotAggregated = /var/lib/datasets/out/wikipedia/letteroutput/aggregated/typoedges

#ChunkCreator class
fileChunkThreashhold = 536870912
#fileChunkThreashhold = 1000000
memoryLimitForWritingFiles = 8388608
